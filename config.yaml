# config for shadow
CFG:
  DEBUG: false
  topk_num_accessible_probs: 10 # topk match with accessible classes logits/probability classes number from the target model. usually top 5 for APIs
  num_epochs: 25 # number of shadow model train epochs
  val_acc_goal: -1 # shadow model's goal accuracy working as early stop. -1 for not using early stop
  num_shadow_models: 100
  shadow_train_size: 2500 # number of datasets to divide CIFAR train dataset for shadow model training
  target_train_size: 7500 # fraction to divide CIFAR test dataset for target model training
  seed: 42
  num_classes: 10 # CIFAR10 vs CIFAR100 selection
  learning_rate: 0.005 # Efficientnet Learning rate
  weight_decay: 0.00005 # default lr: wd ratio is 0.1(https://github.com/clovaai/AdamP), but using 0.01 for small dataset
  input_resolution: 32 # 32 x 32 is cifar10 and cifar100 original image resolution
  train_batch_size: 1024
  val_batch_size: 512
  logging_steps: 1000
  save_path: ./ckpt
  model_architecture: resnet18
  bool_pretrained: false
# config for attack model

CFG_ATTACK:
  attack_dset_path: ./attack/ResNet_pretrained_False_num_shadow_32.csv
  test_size: 0.2
  n_estimators: 100
  attack_model_path: ./attack/XGBClassifier.joblib
